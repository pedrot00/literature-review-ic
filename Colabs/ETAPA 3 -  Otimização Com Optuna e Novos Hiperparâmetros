{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOIdflT5MGtP9Wh8IwhPIRi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# OBJETIVO:\n","\n","1. Apresentar otimização de predição utilizando a biblioteca Optuna;\n","2. Apresentar refatoração das predições utilizando novos hiperparâmetros;\n","\n","Os resultados obtidos na Etapa 2 foram relevantes para uma análise inicial das variáveis de entrada. Nessa fase, cada saída foi avaliada individualmente por meio das métricas R², MAE e RMSE.\n","\n","O objetivo da etapa atual é aprofundar a investigação, realizando novas observações e executando scripts capazes de aprimorar as métricas estatísticas escolhidas. Para isso, utilizou-se o otimizador Optuna, responsável por gerar configurações iniciais relacionadas a forma de particionamento dos dados e a permutação dos hiperparâmetros.\n","\n","Na sequência, procedeu-se a refatoração dos testes da Etapa 2, agora utilizando os hiperparâmetros sugeridos pelo processo de otimização.\n","\n","A definição desses hiperparâmetros foi fundamentada nas diretrizes apresentadas no artigo referenciado abaixo, o qual oferece informações essenciais sobre a potencialização do desempenho de modelos de Random Forest e sobre o comportamento desse algoritmo diante das particularidades das amostras analisadas.\n","\n","[RANDOM FORESTS](https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf)\n","\n","O banco de dados utilizado está disponível no seguinte link:\n","\n","[Banco Áreas de Ponderação MG 2010](https://github.com/pedrot00/ic-deficit-habitacional/blob/master/BDD/BD_MG_DEFICIT1.csv)\n","\n","\n","Para referência detalhada das colunas, pode-se consultar:\n","\n","[Banco Áreas de Ponderação MG 2010 Nomeado](https://github.com/pedrot00/ic-deficit-habitacional/blob/master/BDD/BD_MG_DEFICIT.csv)\n"],"metadata":{"id":"oBmQNqa7PHyp"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","import optuna\n","import warnings\n","warnings.filterwarnings('ignore')\n"],"metadata":{"id":"jNxQS6nWPKFL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["O código a seguir define parâmetros globais que o restante do código irá utilizar. São apenas variáveis comuns, usadas como configurações fixas para o experimento.\n","\n","- CV_FOLDS determina a quantidade de folds da validação cruzada, o dataset de entrada é dividido 5 partes de tamanho iguais, é treinado um modelo particular de floresta aleatória para cada folder.\n","\n","- N_TRIALS determina a quantidade de permutações de hiperparâmetros que será utilizado pelo Optuna em busca da melhor combinação de hiperparâmetros.\n","\n","- TEST_SIZE determina relação de dados para teste e treino, neste caso é uma relação 80 pra 20: 80% dos dados para treinamento em cada folder e 20% para teste.\n","- RANDOM_STATE determina a semente de todos os geradores de números, garantindo reprodutibilidade do experimento."],"metadata":{"id":"wJhMOed6PMJD"}},{"cell_type":"code","source":["# CONFIGURAÇÕES OTIMIZADAS\n","CV_FOLDS = 5\n","N_TRIALS = 80  # Aumentei para compensar busca mais inteligente\n","TEST_SIZE = 0.2\n","RANDOM_STATE = 42"],"metadata":{"id":"CyrQhWgFPMej"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# CARREGA DADOS\n","url = \"https://raw.githubusercontent.com/pedrot00/ic-deficit-habitacional/master/BDD/BD_MG_DEFICIT1.csv\"\n","dados = pd.read_csv(url)\n","\n","dados = dados.dropna(subset=[\"DOMICILIOS_PRECARIOS\", \"COABITACAO\", \"ONUS_EXCESSIVO\",\n","                               \"ADENSAMENTO\", \"DEFICIT_TOTAL\"])\n","\n","saidas = [\"DOMICILIOS_PRECARIOS\", \"COABITACAO\", \"ONUS_EXCESSIVO\", \"ADENSAMENTO\", \"DEFICIT_TOTAL\"]\n","entradas = [col for col in dados.columns if col not in saidas]\n","X = dados[entradas]"],"metadata":{"id":"PZ9uvimHPMsH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A função a seguir define a função objetivo do Optuna, responsável por selecionar automaticamente os hiperparâmetros do modelo dentro de intervalos previamente estabelecidos. Esses intervalos limitam o espaço de busca e evitam configurações excessivamente complexas ou computacionalmente ineficientes.\n","\n","- n_estimators: número de árvores da floresta, variando entre 100 e 300. Valores menores atendem relações menos complexas, enquanto valores maiores permitem capturar padrões mais específicos. Um número excessivo de árvores pode gerar modelos redundantes, aumentando o custo computacional sem ganhos significativos de desempenho.\n","\n","- max_depth: profundidade máxima das árvores, controlando diretamente a complexidade do modelo. Profundidades maiores aumentam a capacidade de ajuste, mas também o risco de sobreajuste.\n","\n","- min_samples_split e min_samples_leaf: definem o número mínimo de amostras para dividir um nó e para formar uma folha, respectivamente, atuando como mecanismos de regularização.\n","\n","- max_features: controla a quantidade de atributos considerados em cada divisão, influenciando a diversidade das árvores e reduzindo correlação entre elas.\n","\n","- bootstrap: define se as amostras são geradas com reposição, permitindo ao Optuna decidir a estratégia mais adequada.\n","\n","A avaliação é realizada por validação cruzada, utilizando simultaneamente MAE e R². A função objetivo combina ambas as métricas, atribuindo maior peso ao R², de modo que o processo de otimização minimize o erro absoluto médio e maximize a capacidade explicativa do modelo."],"metadata":{"id":"GpDuCw87POnA"}},{"cell_type":"code","source":["def objetivo_optuna_multimetric(trial, X_train, y_train, target_name):\n","    params = {\n","        'n_estimators': trial.suggest_int('n_estimators', 100, 300),  # Aumentei range superior\n","        'max_depth': trial.suggest_categorical('max_depth', [None, 15, 25, 35, 50]),  # Mais opções de profundidade\n","        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n","        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n","        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', 0.7, 0.8]),  # Novas opções de repartição\n","        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),  # Optuna decide\n","        'random_state': RANDOM_STATE,\n","        'n_jobs': -1\n","    }\n","\n","    modelo = RandomForestRegressor(**params)\n","\n","    # AVALIAÇÃO MULTI-MÉTRICA na validação cruzada\n","    scores_mae = cross_val_score(modelo, X_train, y_train, cv=CV_FOLDS,\n","                                scoring='neg_mean_absolute_error', n_jobs=-1)\n","    scores_r2 = cross_val_score(modelo, X_train, y_train, cv=CV_FOLDS,\n","                               scoring='r2', n_jobs=-1)\n","\n","    mae_cv = -scores_mae.mean()\n","    r2_cv = scores_r2.mean()\n","\n","    # FUNÇÃO OBJETIVO: Minimizar MAE e Maximizar R²\n","    # Peso maior no R² pois você mencionou que é importante\n","    objetivo = mae_cv * 0.3 + (1 - r2_cv) * 0.7  # Queremos minimizar esta combinação\n","\n","    # Guarda métricas para análise\n","    trial.set_user_attr('r2_cv', r2_cv)\n","    trial.set_user_attr('mae_cv', mae_cv)\n","\n","    return objetivo"],"metadata":{"id":"k0fPjl91PQM5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Inicialmente, a variável alvo correspondente é selecionada a partir do conjunto de dados. Em seguida, os dados são divididos em conjuntos de treinamento e teste, garantindo reprodutibilidade por meio da fixação da semente aleatória.\n","\n","Na etapa seguinte, é criado um estudo de otimização com o Optuna, utilizando o amostrador TPE para explorar o espaço de hiperparâmetros. A função objetivo é então otimizada ao longo de múltiplas iterações, empregando validação cruzada e uma métrica combinada que considera simultaneamente o erro absoluto médio e o coeficiente de determinação.\n","\n","Após a otimização, o modelo é treinado novamente utilizando os melhores hiperparâmetros encontrados. Por fim, o desempenho do modelo é avaliado no conjunto de teste por meio das métricas MAE, RMSE e R², que quantificam, respectivamente, o erro médio, a penalização de erros maiores e a capacidade explicativa do modelo."],"metadata":{"id":"pu0LdUXtPSPP"}},{"cell_type":"code","source":["def otimizar_modelo(y_col):\n","    y = dados[y_col]\n","\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n","    )\n","\n","    study = optuna.create_study(\n","        direction='minimize',\n","        sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE)\n","    )\n","\n","    study.optimize(\n","        lambda trial: objetivo_optuna_multimetric(trial, X_train, y_train, y_col),\n","        n_trials=N_TRIALS,\n","        show_progress_bar=False\n","    )\n","\n","    # Treinamento final com melhores hiperparâmetros\n","    best_params = study.best_params\n","    best_params.update({\n","        'random_state': RANDOM_STATE,\n","        'n_jobs': -1\n","    })\n","\n","    modelo_final = RandomForestRegressor(**best_params)\n","    modelo_final.fit(X_train, y_train)\n","\n","    # Avaliação no conjunto de teste\n","    y_pred = modelo_final.predict(X_test)\n","\n","    metricas = {\n","        'MAE': mean_absolute_error(y_test, y_pred),\n","        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),\n","        'R2': r2_score(y_test, y_pred)\n","    }\n","\n","    return metricas, best_params"],"metadata":{"id":"HRMwq_fePSWH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Após a definição da função de otimização, o procedimento é executado para cada variável alvo de forma independente. Para cada saída, o modelo é otimizado, avaliado e suas métricas de desempenho são armazenadas.\n","\n","Os resultados obtidos para MAE, RMSE e R² são organizados em uma estrutura tabular, permitindo a comparação direta do desempenho do modelo entre as diferentes variáveis alvo. Essa organização facilita a análise global dos resultados e a interpretação do impacto da otimização em cada saída."],"metadata":{"id":"ZRJyMI5sPT9n"}},{"cell_type":"code","source":["resultados = {}\n","melhores_parametros = {}\n","\n","for col in saidas:\n","    metricas, params = otimizar_modelo(col)\n","    resultados[col] = metricas\n","    melhores_parametros[col] = params\n","\n","df_resultados = pd.DataFrame(resultados).T\n","df_resultados\n"],"metadata":{"id":"FPCP4CcmPU_t"},"execution_count":null,"outputs":[]}]}